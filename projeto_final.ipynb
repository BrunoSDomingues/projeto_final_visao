{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimento de veículos na estrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto foi desenvolvido um programa que destaca veículos passando por uma região específica de uma estrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-Qx-qSM8ngHW"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracker\n",
    "\n",
    "O tracker do projeto utiliza o conceito de distância euclideana para determinar a distância entre objetos em diferentes frames.\n",
    "\n",
    "A distância euclideana é a distância retilínea entre dois pontos distintos, que segue a fórmula abaixo.\n",
    "\n",
    "$d(p, q) = d(q, p) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + (p_3 - q_3)^2 + ... + (p_n - q_n)^2} = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}$\n",
    "\n",
    "Uma vez que a distância estiver calculada, existem dois cenários:\n",
    "\n",
    "1. A distância é pequena $\\rightarrow$ mesmo objeto\n",
    "2. A distância é grande $\\rightarrow$ objetos distintos\n",
    "\n",
    "Para cada objeto é atribuido um ID, que facilita a identificação de objetos distintos, e os valores de centro são atribuídos constantemente ao objeto, de modo a acompanhar sua posição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-armGTAU56VO"
   },
   "outputs": [],
   "source": [
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center of each object\n",
    "        # key = object id\n",
    "        # value = center coordinates\n",
    "        self.centers = {}\n",
    "\n",
    "        # ID counter\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # List that stores the objects coordinates and id\n",
    "        objects = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            # Getting rectangle properties\n",
    "            x, y, w, h = rect\n",
    "            x_center = (2 * x + w) // 2\n",
    "            y_center = (2 * y + h) // 2\n",
    "\n",
    "            # Flag for repeated object\n",
    "            same_object = False             \n",
    "\n",
    "            # Iterating over all points\n",
    "            for id, pt in self.centers.items():\n",
    "\n",
    "                # Calculating Euclidean distance\n",
    "                dist = math.hypot(x_center - pt[0], y_center - pt[1])\n",
    "\n",
    "                # Check the distance\n",
    "                if dist < 25:\n",
    "                    self.centers[id] = (x_center, y_center)\n",
    "                    print(f\"Objects: {self.centers}\")\n",
    "                    objects.append((x, y, w, h, id))\n",
    "                    \n",
    "                    # Setting same_object so we keep the original ID\n",
    "                    same_object = True\n",
    "                    break\n",
    "\n",
    "            # Assign an ID for the new object\n",
    "            if not same_object:\n",
    "                self.centers[self.id_count] = (x_center, y_center)\n",
    "                objects.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Cleaning up the dictionary to remove IDs out of frame\n",
    "        new_centers = {}\n",
    "        for obj in objects:\n",
    "            object_id = obj[4]\n",
    "            center = self.centers[object_id]\n",
    "            new_centers[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.centers = new_centers.copy()\n",
    "        return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastreando os objetos\n",
    "\n",
    "Após definir nosso tracker, podemos começar a analisar os objetos no vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "10zqy6Nz8caw",
    "outputId": "c03016c0-9ad2-4ebe-f2ba-a410d699ae0e"
   },
   "outputs": [],
   "source": [
    "# Create tracker object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "cap = cv2.VideoCapture(\"highway.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analisar nosso vídeo, fez-se uso de background subtraction com o cv2, de modo a gerar uma máscara que será aplicada em cima do vídeo original, com a finalidade de destacar objetos presentes no vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "10zqy6Nz8caw",
    "outputId": "c03016c0-9ad2-4ebe-f2ba-a410d699ae0e"
   },
   "outputs": [],
   "source": [
    "# Object detection\n",
    "detector = cv2.createBackgroundSubtractorMOG2(\n",
    "    history=100, \n",
    "    varThreshold=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos seguir para nossa análise. Para tal, as etapas realizadas se encontram abaixo.\n",
    "\n",
    "1. Obtém-se o frame do vídeo\n",
    "2. Obtém-se as dimensões do frame\n",
    "3. Define-se uma região de interesse (ROI) na qual serão rastreados os objetos\n",
    "4. Aplica-se o nosso detector/mask no ROI\n",
    "5. Thresholding para remover sombras\n",
    "6. Obtém-se os contornos presentes\n",
    "7. Descarta-se os contornos obtidos que tem área pequena\n",
    "8. Armazena-se os contornos válidos\n",
    "9. Utiliza-se a função `update` do tracker para atualizar os objetos (IDs e posições)\n",
    "10. Mostra-se um retângulo ao redor do objeto e o ID do mesmo\n",
    "\n",
    "No fim, temos 3 janelas do cv2:\n",
    "\n",
    "- janela do ROI\n",
    "- janela do ROI com a máscara\n",
    "- janela do vídeo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "10zqy6Nz8caw",
    "outputId": "c03016c0-9ad2-4ebe-f2ba-a410d699ae0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects: {0: (163, 79)}\n",
      "Objects: {1: (161, 122)}\n",
      "Objects: {1: (163, 127)}\n",
      "Objects: {1: (162, 136)}\n",
      "Objects: {1: (163, 149)}\n",
      "Objects: {1: (160, 144)}\n",
      "Objects: {1: (159, 153)}\n",
      "Objects: {1: (162, 174)}\n",
      "Objects: {1: (160, 168), 2: (158, 148)}\n",
      "Objects: {1: (159, 180)}\n",
      "Objects: {1: (158, 190)}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Extract the ROI\n",
    "    roi = frame[340:720, 500:800]\n",
    "\n",
    "    # Apply our detector in the ROI\n",
    "    mask = detector.apply(roi)\n",
    "\n",
    "    # Thresholding to remove the white generated by the shadow\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Finding contours\n",
    "    contours, _ = cv2.findContours(\n",
    "        mask, \n",
    "        cv2.RETR_TREE, \n",
    "        cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # Store all detections\n",
    "    detections = []\n",
    "\n",
    "    # Iterating over contours\n",
    "    for cnt in contours:\n",
    "        # Calculate contour area\n",
    "        area = cv2.contourArea(cnt)                 \n",
    "\n",
    "        # Discarding small objects\n",
    "        if area > 100:\n",
    "            # Create a rectangle\n",
    "            x, y, w, h = cv2.boundingRect(cnt)      \n",
    "            detections.append((x, y, w, h))         \n",
    "\n",
    "    # Updating the IDs using the tracker\n",
    "    objects = tracker.update(detections)\n",
    "    for obj in objects:\n",
    "        x, y, w, h, id = obj\n",
    "        cv2.putText(\n",
    "            roi,\n",
    "            str(id),\n",
    "            (x, y - 15),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2,\n",
    "            (255, 0, 0),\n",
    "            2\n",
    "        )\n",
    "        cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Region Of Interest\", roi)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "Pode-se afirmar que obteve-se bons resultados no projeto: o tracker foi capaz de identificar veículos com sucesso na região delimitada pelo ROI. No entanto, ainda houveram casos em que o tracker identificou objetos que não eram veículos. Outro fator relevante é que próximo ao fim do vídeo a câmera se mexe, o que desestabiliza os cálculos.\n",
    "\n",
    "Para próximas iterações, pode-se fazer uma análise no espectro de cores, de modo a identificar somente os veículos de cor vermelha, por exemplo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "projeto_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
